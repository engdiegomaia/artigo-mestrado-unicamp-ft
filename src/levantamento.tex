%% Capítulo 2: Revisão Bibliográfica e Estado da Arte
%% Baseado na análise sistemática de 20 artigos científicos

\section{Visão Geral do Estado da Arte}

Esta revisão bibliográfica baseia-se na análise sistemática de 20 artigos científicos selecionados por sua relevância para processamento hiperespectral embarcado, organizados por nível de contribuição direta ao problema de pesquisa. A metodologia de seleção priorizou trabalhos publicados entre 2019-2024 que demonstram técnicas comprovadas de otimização energética e redução de latência em sistemas embarcados.

\subsection{Categorização dos Trabalhos Analisados}

Os artigos foram classificados em três categorias principais:

\textbf{Muito Alta Relevância (⭐⭐⭐⭐⭐)}: 4 artigos que demonstram implementações práticas de otimização em sistemas embarcados com métricas quantitativas de performance.

\textbf{Alta Relevância (⭐⭐⭐⭐)}: 4 artigos que fornecem revisões sistemáticas abrangentes ou técnicas específicas aplicáveis ao problema.

\textbf{Relevância Média (⭐⭐⭐)}: 12 artigos que contribuem com técnicas complementares, fundamentos teóricos ou validações específicas.

\section{Trabalhos de Muito Alta Relevância}

\subsection{Compressive Sensing Hiperespectral Embarcado}

Lim et al. \cite{lim2022} apresentam o primeiro estudo sistemático sobre viabilidade de compressive sensing (CS) hiperespectral em sistemas embarcados para aplicações em tempo real. O trabalho foca no algoritmo CGNE (Conjugate Gradient for Normal Equation) implementado em sistema DDCASSI, estabelecendo uma metodologia de análise que se tornou referência na área.

\textbf{Contribuições Principais}:
\begin{itemize}
\item Análise teórica de complexidade O(n³) do CGNE com caracterização detalhada de requisitos de memória e bandwidth
\item Demonstração de redução de 50-70\% no volume de dados sem perda significativa de qualidade
\item Identificação da sparsity da matriz do sistema como fator fundamental para redução computacional
\item Estabelecimento de latência <10ms como viável para reconstrução de imagens pequenas
\item Confirmação de que GPUs/FPGAs são necessárias para atingir performance de tempo real (25 fps)
\end{itemize}

\textbf{Relevância para a Pesquisa}: O framework de análise proposto pelos autores fornece a base metodológica para avaliar viabilidade de algoritmos embarcados, enquanto as técnicas de exploração de sparsity são diretamente aplicáveis ao módulo GPU do sistema proposto.

\subsection{Codesign HW/SW para Compressão Lossless}

Hwang et al. \cite{hwang2011} demonstram uma implementação exemplar de codesign HW/SW para compressão lossless hiperespectral, estabelecendo metodologia sistemática que resultou em melhorias de eficiência energética de 43.5x comparado a servidores convencionais.

\textbf{Metodologia e Resultados}:
\begin{itemize}
\item Profiling sistemático identificou predição inter-banda como responsável por 91\% do tempo computacional
\item Particionamento inteligente HW/SW baseado em análise quantitativa de gargalos
\item Implementação FPGA Spartan3 XC3S4000 atingiu throughput de 16.5 M pixels/s
\item Speedup de 21x comparado à implementação puramente software
\item Otimizações sistemáticas: memória hierárquica, DMA, e opções de compiler específicas
\end{itemize}

\textbf{Relevância para a Pesquisa}: A metodologia de profiling e particionamento HW/SW proposta é diretamente aplicável ao desenvolvimento do sistema heterogêneo, fornecendo tanto o framework de análise quanto as técnicas específicas de otimização.

\subsection{Compressão Real-Time em GPUs Embarcadas}

Díaz et al. \cite{diaz2019} implementaram o algoritmo HyperLCA em GPUs embarcadas NVIDIA Jetson, demonstrando pela primeira vez compressão lossy hiperespectral em tempo real em plataformas embarcadas com validação em aplicação real de agricultura.

\textbf{Implementação e Performance}:
\begin{itemize}
\item Análise detalhada revelou que HyperLCA Transform consome >95\% do processamento total
\item Implementação CUDA com 7 kernels especializados para arquiteturas Kepler (TK1) e Pascal (TX2)
\item Performance de 330 fps para dados de 144.375 MB/s com taxa de compressão >20:1
\item Speedup de 21x sobre implementação CPU com eficiência energética 4.1x superior
\item Validação prática: câmera 224 bandas, 1024 pixels, aplicação agricultura UAV
\end{itemize}

\textbf{Relevância para a Pesquisa}: As técnicas de implementação CUDA e a metodologia de análise de FLOPs são diretamente aplicáveis ao módulo GPU, enquanto a validação em agricultura UAV fornece benchmarks práticos para comparação.

\subsection{Acelerador SVM Hardware para Classificação}

Martins et al. \cite{martins2019} desenvolveram um acelerador hardware SVM especializado para classificação onboard, demonstrando tempo de classificação de 0.1ms/pixel com 99.7\% de precisão usando técnicas de seleção inteligente de bandas.

\textbf{Técnicas e Resultados}:
\begin{itemize}
\item Implementação do método EMCR (Entropy Multiple Correlation Ratio) para seleção de bandas, reduzindo 80\% do processamento
\item Classificador SVM com distância de Hamming para decisão ultrarrápida em hardware
\item Duas arquiteturas FPGA: single-core (17\% DSPs) e hexa-core (100\% DSPs)
\item Speedup de 13x comparado à implementação MATLAB
\item Processamento de dataset AVIRIS completo em tempo real
\end{itemize}

\textbf{Relevância para a Pesquisa}: O método EMCR é fundamental para o módulo FPGA proposto, enquanto a implementação SVM otimizada fornece a base para o módulo CPU de classificação.

\section{Trabalhos de Alta Relevância}

\subsection{Revisões Sistemáticas e Estado da Arte}

Lou et al. \cite{lou2024} conduziram uma revisão sistemática de 200+ artigos sobre classificação LULC usando imagens hiperespectrais, identificando três gerações de métodos e estabelecendo que deep learning representa o estado da arte atual. A revisão identifica que arquiteturas híbridas (CNN+Transformer) mostram resultados promissores, enquanto o processamento em tempo real permanece como desafio técnico significativo.

O trabalho de Zhang et al. \cite{uav_review_2024} foca especificamente em classificação hiperespectral para UAV, identificando desafios únicos como ruído dinâmico, pixels mistos e variabilidade temporal. Os autores demonstram que CNNs 3D são superiores para dados hiperespectrais UAV quando combinadas com mecanismos de atenção.

\subsection{Arquiteturas Ultra-Eficientes}

O TakuNet \cite{takunet2025} representa um avanço significativo em eficiência computacional, apresentando arquitetura CNN com apenas 37.685 parâmetros (redução de 99\%) que mantém F1-score de 0.943. A arquitetura utiliza depth-wise convolutions e early downsampling, atingindo >650 fps no Jetson Orin Nano com 21x redução no consumo energético.

\textbf{Técnicas Aplicáveis}:
\begin{itemize}
\item Depth-wise convolutions para redução drástica de parâmetros
\item Early downsampling para redução computacional inicial
\item Treinamento FP16 para otimização em aceleradores embarcados
\item Conexões densas para convergência rápida
\end{itemize}

\subsection{Benchmarks em Plataformas Embarcadas}

Ullah et al. \cite{ullah2020} fornecem benchmark sistemático de plataformas NVIDIA Jetson (Nano, TX1, Xavier) para deep learning, demonstrando que o Xavier oferece melhor performance geral e que TensorFlow-GPU utiliza recursos mais eficientemente que implementações CPU.

\section{Técnicas de Otimização Identificadas}

\subsection{Estratégias de Redução de Consumo Energético}

A análise sistemática identificou quatro estratégias principais comprovadas:

\begin{enumerate}
\item \textbf{Codesign HW/SW}: Hwang et al. demonstraram melhoria de 43.5x na eficiência energética através de particionamento sistemático e implementação FPGA de módulos críticos.

\item \textbf{Seleção Inteligente de Bandas}: O método EMCR de Martins et al. reduz 80\% do processamento mantendo 99.7\% de precisão.

\item \textbf{Precisão Reduzida}: Múltiplos trabalhos confirmam que FP16 oferece redução de 50\% no uso de memória com perda <1\% na precisão.

\item \textbf{Compressive Sensing}: Lim et al. demonstraram redução de 50-70\% no volume de dados com reconstrução viável em <10ms.
\end{enumerate}

\subsection{Estratégias de Redução de Latência}

Três abordagens principais foram identificadas:

\begin{enumerate}
\item \textbf{Paralelização Massiva}: Díaz et al. atingiram 330 fps através de implementação CUDA otimizada com múltiplos níveis de paralelismo.

\item \textbf{Aceleradores Especializados}: Martins et al. demonstraram 0.1ms/pixel usando FPGA especializada para classificação SVM.

\item \textbf{Algoritmos Otimizados}: CGNE para compressive sensing e HyperLCA para compressão demonstraram ser adequados para implementação embarcada.
\end{enumerate}

\section{Gaps e Oportunidades na Literatura}

\subsection{Ausência de Frameworks Integrados}

Embora existam soluções pontuais eficazes (GPU \cite{diaz2019}, FPGA \cite{hwang2011}, algoritmos específicos \cite{lim2022}), não há frameworks que integrem sistematicamente múltiplas técnicas de otimização. Esta lacuna representa a principal oportunidade para contribuição original.

\subsection{Limitações em Validação Prática}

A maioria dos trabalhos limita-se a validações em datasets sintéticos. Apenas Díaz et al. \cite{diaz2019} e Shin et al. \cite{shin2024} demonstram aplicações práticas, indicando necessidade de mais validações em cenários reais.

\subsection{Trade-offs Não Quantificados}

As relações precisão vs consumo vs latência são raramente caracterizadas quantitativamente. Hwang et al. \cite{hwang2011} e Martins et al. \cite{martins2019} fornecem análises parciais, mas falta uma caracterização sistemática.

\subsection{Metodologias de Codesign Limitadas}

Embora Hwang et al. \cite{hwang2011} demonstrem metodologia eficaz, ela é específica para compressão lossless. Faltam metodologias generalizáveis para outros algoritmos hiperespectrais.

\section{Benchmarks e Métricas de Referência}

\subsection{Performance Estabelecida}

Com base na literatura analisada, os seguintes benchmarks representam o estado da arte:

\begin{itemize}
\item \textbf{Throughput}: 330 fps (Díaz et al., Jetson TX2) para compressão
\item \textbf{Latência}: 0.1ms/pixel (Martins et al., FPGA) para classificação
\item \textbf{Precisão}: 99.7\% (Martins et al.) com recursos limitados
\item \textbf{Eficiência Energética}: 43.5x melhoria (Hwang et al.) via codesign
\item \textbf{Redução de Dados}: 50-70\% (Lim et al.) via compressive sensing
\end{itemize}

\subsection{Datasets de Validação}

Os trabalhos analisados utilizam consistentemente três datasets principais:

\begin{itemize}
\item \textbf{AVIRIS Indian Pines}: Dataset padrão para classificação (614×512×224)
\item \textbf{Pavia University}: Validação em ambiente urbano
\item \textbf{Salinas Valley}: Aplicações agrícolas
\end{itemize}

\section{Síntese e Direcionamentos}

A análise sistemática da literatura revela que existe base técnica sólida para desenvolver sistemas hiperespectrais embarcados otimizados, mas as soluções existentes são fragmentadas. As técnicas individuais demonstram eficácia comprovada:

\begin{itemize}
\item Compressive sensing reduz dados em 50-70\% \cite{lim2022}
\item Seleção EMCR reduz processamento em 80\% \cite{martins2019}
\item Codesign HW/SW melhora eficiência em 43.5x \cite{hwang2011}
\item Implementações GPU embarcadas atingem 330 fps \cite{diaz2019}
\end{itemize}

A principal lacuna identificada é a ausência de um framework que integre sistematicamente estas técnicas em um sistema heterogêneo otimizado. Esta lacuna representa a oportunidade central para contribuição original desta pesquisa.

O próximo capítulo apresenta a metodologia proposta para desenvolver tal framework integrado, baseando-se nas técnicas comprovadas identificadas nesta revisão e endereçando especificamente as lacunas identificadas na literatura atual.